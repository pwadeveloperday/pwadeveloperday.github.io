window.__sveltekit_data = (function(a,b,c,d){return {type:c,nodes:[null,{type:c,data:{PostContent:"\u003Cp\u003E在 Microsoft 2023 Build 大会上，Panos Panay 宣布 ONNX Runtime 作为 Windows AI 的 Gateway。 ONNX Runtime 可以跨 CPU、GPU、NPU 或与 Azure 混合在任何 Windows 或其他设备上运行 AI 模型。 微软还推出了 Olive 工具链，旨在减轻开发人员为各种 Windows 和其他设备优化模型的负担。 ONNX Runtime 和 Olive 都有助于加快将 AI 模型部署到应用中的速度。\u003C\u002Fp\u003E\n\u003Cp\u003E在多个演讲中，微软提到还支持使用 ONNX Runtime Web 在浏览器中进行推理，并正在与伙伴英特尔合作整合 WebNN。\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cimg src=\"\u002Fimages\u002Fblog\u002F20230530\u002Fwebnn_build2.png\" alt=\"1\"\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E微软 Principal PM Jeff Mendenhall 提到：\u003C\u002Fp\u003E\n\u003Cblockquote\u003E\u003Cp\u003EWe’re also working on a WebNN so that you can continue with Web ORT that exists today.\nIt can do local inferencing in-browser.\nWe’re also implementing the WebNN standard, and we’re working with Intel so once all of code changes get approved, it’s coming soon at this point. \u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\n\u003Cblockquote\u003E\u003Cp\u003E我们还在开发 WebNN，以便您可以继续使用目前存在的 ONNX Runtime Web。\n它可以在浏览器中进行本地推理。\n我们也在实施 WebNN 标准，我们正在与英特尔合作，因此一旦所有代码更改获得批准，它很快就会出现。\u003C\u002Fp\u003E\u003C\u002Fblockquote\u003E\n\u003Cp\u003E\u003Cimg src=\"\u002Fimages\u002Fblog\u002F20230530\u002Fwebnn_build3.png\" alt=\"1\"\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E微软 CVP Pavan Davuluri 在 Microsoft Build 2023 第二天的演讲中提到, 除了 CPU, GPU 之外, 专有的 NPU AI 硬件加速器正在不断地进入到 Windows 生态，多家厂商均进行了支持，而支持 NPU 的 WebNN API 也将很快到来。\u003C\u002Fp\u003E\n\u003Ch2 id=\"演讲回放\"\u003E\u003Ca aria-hidden=\"true\" tabindex=\"-1\" href=\"#演讲回放\"\u003E\u003Cspan class=\"icon icon-link\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E演讲回放\u003C\u002Fh2\u003E\n\u003Cul\u003E\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fblogs.windows.com\u002Fwindowsdeveloper\u002F2023\u002F05\u002F23\u002Funlocking-the-end-to-end-windows-ai-developer-experience-using-onnx-runtime-and-olive\u002F\" rel=\"nofollow\"\u003EUnlocking the end-to-end Windows AI developer experience using ONNX runtime and Olive\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fbuild.microsoft.com\u002Fen-US\u002Fsessions\u002F0ea15726-1273-4a7c-a71a-efc635172a3b?source=sessions\" rel=\"nofollow\"\u003EDeliver AI-powered experiences across cloud and edge, with Windows\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=R5YmXKB5Z5o&t=5796s\" rel=\"nofollow\"\u003EShaping the future of work with AI\u003C\u002Fa\u003E\u003C\u002Fli\u003E\u003C\u002Ful\u003E",meta:{title:"Microsoft 2023 Build: 用于浏览器推理的 ONNX Runtime Web 框架及 WebNN 整合",date:d,updated:d,categories:["WebNN","WebML"],coverImage:"\u002Fimages\u002Fblog\u002F20230530\u002Fwebnn_build1.png",coverWidth:16,coverHeight:9,excerpt:"在 Microsoft 2023 Build 大会上，Panos Panay 宣布 ONNX Runtime 作为 Windows AI 的 Gateway。 ONNX Runtime 可以跨 CPU、GPU、NPU 或与 Azure 混合在任何 Windows 或其他设备上运行 AI 模型。 微软提到还支持使用 ONNX Runtime Web 在浏览器中进行推理，并正在与合作伙伴英特尔合作整合 WebNN。",author:"PWA",authorTitle:a,authorCompany:"中国 PWA 开发者日",authorImg:"\u002Fimages\u002Fpeople\u002F120\u002Fpwadev.png",author2:a,authorTitle2:a,authorCompany2:a,authorImg2:a,author3:a,authorTitle3:a,authorCompany3:a,authorImg3:a,slug:"microsoft-build-2023-webnn"}},uses:{dependencies:b,params:["post"],parent:b,url:b}}]}}("",void 0,"data","2023-05-30"))